{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('H:/ml-100k/u.data', sep='\\t', names=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users = 943 | Number of movies = 1682\n"
     ]
    }
   ],
   "source": [
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "print ('Number of users = ' + str(n_users) + ' | Number of movies = ' + str(n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation as cv\n",
    "train_data, test_data = cv.train_test_split(df, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.  3.  0. ...,  0.  0.  0.]\n",
      " [ 4.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 5.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  5.  0. ...,  0.  0.  0.]]\n",
      "[[ 0.  0.  4. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#Memory Based\n",
    "\n",
    "#Create two user-item matrices, one for training and another for testing\n",
    "train_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in train_data.itertuples():\n",
    "    train_data_matrix[line[1]-1, line[2]-1] = line[3]\n",
    "\n",
    "test_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in test_data.itertuples():\n",
    "    test_data_matrix[line[1]-1, line[2]-1] = line[3]\n",
    "    \n",
    "print (train_data_matrix)\n",
    "print (test_data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.85893314  0.98960083 ...,  0.92999753  0.86784395\n",
      "   0.70414727]\n",
      " [ 0.85893314  0.          0.97988022 ...,  0.80153321  0.90653031\n",
      "   0.94235079]\n",
      " [ 0.98960083  0.97988022  0.         ...,  0.9736328   0.88662572  1.        ]\n",
      " ..., \n",
      " [ 0.92999753  0.80153321  0.9736328  ...,  0.          0.97098849\n",
      "   0.928715  ]\n",
      " [ 0.86784395  0.90653031  0.88662572 ...,  0.97098849  0.          0.85312118]\n",
      " [ 0.70414727  0.94235079  1.         ...,  0.928715    0.85312118  0.        ]]\n",
      "[[ 0.          0.68242707  0.76228579 ...,  1.          0.94457792  1.        ]\n",
      " [ 0.68242707  0.          0.74138164 ...,  1.          0.91240643\n",
      "   0.91240643]\n",
      " [ 0.76228579  0.74138164  0.         ...,  1.          1.          0.88835156]\n",
      " ..., \n",
      " [ 1.          1.          1.         ...,  0.          1.          1.        ]\n",
      " [ 0.94457792  0.91240643  1.         ...,  1.          0.          1.        ]\n",
      " [ 1.          0.91240643  0.88835156 ...,  1.          1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "user_similarity = pairwise_distances(train_data_matrix, metric='cosine')\n",
    "item_similarity = pairwise_distances(train_data_matrix.T, metric='cosine')\n",
    "\n",
    "print (user_similarity)\n",
    "print (item_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, type='user'):\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        #You use np.newaxis so that mean_user_rating has same format as ratings\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.38303414  0.39003859  0.41779599 ...,  0.45922246  0.45015666\n",
      "   0.44579602]\n",
      " [ 0.08596167  0.09910549  0.0963776  ...,  0.09953534  0.10073425\n",
      "   0.10108989]\n",
      " [ 0.05435555  0.0569474   0.05391551 ...,  0.05208471  0.05529066\n",
      "   0.05536142]\n",
      " ..., \n",
      " [ 0.03132754  0.03912343  0.03788369 ...,  0.04479157  0.04391392\n",
      "   0.04391478]\n",
      " [ 0.11536825  0.12259707  0.12926399 ...,  0.13379592  0.1330611\n",
      "   0.13353281]\n",
      " [ 0.21077053  0.2026069   0.22427093 ...,  0.26191712  0.2540892\n",
      "   0.25451158]]\n",
      "[[ 1.55437986  0.60111124  0.49766422 ...,  0.30766763  0.30765272\n",
      "   0.30751807]\n",
      " [ 1.25267872  0.30126524  0.14991276 ..., -0.06559955 -0.06435775\n",
      "  -0.06414722]\n",
      " [ 1.26727097  0.25416574  0.10488549 ..., -0.11356036 -0.111789   -0.111738  ]\n",
      " ..., \n",
      " [ 1.14641512  0.23187527  0.08228055 ..., -0.1200224  -0.11927425\n",
      "  -0.11913055]\n",
      " [ 1.30412294  0.31464514  0.18928677 ..., -0.02471823 -0.02383961\n",
      "  -0.02372699]\n",
      " [ 1.36880542  0.3939633   0.29361678 ...,  0.11021199  0.11018769\n",
      "   0.11036611]]\n"
     ]
    }
   ],
   "source": [
    "item_prediction = predict(train_data_matrix, item_similarity, type='item')\n",
    "user_prediction = predict(train_data_matrix, user_similarity, type='user')\n",
    "\n",
    "print (item_prediction)\n",
    "print (user_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))\n",
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF RMSE: 3.127978924337624\n",
      "Item-based CF RMSE: 3.457999108515081\n"
     ]
    }
   ],
   "source": [
    "print ('User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))\n",
    "print ('Item-based CF RMSE: ' + str(rmse(item_prediction, test_data_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MODEL BASED\n",
    "sparsity=round(1.0-len(df)/float(n_users*n_items),3)\n",
    "print 'The sparsity level of MovieLens100K is ' +  str(sparsity*100) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF MSE: 2.724406819215572\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "#get SVD components from train matrix. Choose k.\n",
    "u, s, vt = svds(train_data_matrix, k = 20)\n",
    "s_diag_matrix=np.diag(s)\n",
    "X_pred = np.dot(np.dot(u, s_diag_matrix), vt)\n",
    "print ('User-based CF MSE: ' + str(rmse(X_pred, test_data_matrix)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
